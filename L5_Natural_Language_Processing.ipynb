{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L5_Natural Language Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEJ9AbdryaPg6vcTqrpyMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/momijizen/tensorflow-introduction/blob/main/L5_Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHI7xdO1xoRS"
      },
      "source": [
        "\r\n",
        "#Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1kbZWt2xp8w"
      },
      "source": [
        "###Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnW2WT7AxvU5",
        "outputId": "52310d0a-6701-4999-c8ad-284a2c43bc5b"
      },
      "source": [
        "vocab = {}  # maps word to integer representing it\r\n",
        "word_encoding = 1\r\n",
        "def bag_of_words(text):\r\n",
        "  global word_encoding\r\n",
        "\r\n",
        "  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\r\n",
        "  bag = {}  # stores all of the encodings and their frequency\r\n",
        "\r\n",
        "  for word in words:\r\n",
        "    if word in vocab:\r\n",
        "      encoding = vocab[word]  # get encoding from vocab\r\n",
        "    else:\r\n",
        "      vocab[word] = word_encoding\r\n",
        "      encoding = word_encoding\r\n",
        "      word_encoding += 1\r\n",
        "    \r\n",
        "    if encoding in bag:\r\n",
        "      bag[encoding] += 1\r\n",
        "    else:\r\n",
        "      bag[encoding] = 1\r\n",
        "  \r\n",
        "  return bag\r\n",
        "\r\n",
        "text = \"this is a test to see if this test will work is is test a a\"\r\n",
        "bag = bag_of_words(text)\r\n",
        "print(bag)\r\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffUuK7y7zXrQ",
        "outputId": "c5b42a82-d239-401c-a910-e0268a23634c"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\r\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\r\n",
        "\r\n",
        "pos_bag = bag_of_words(positive_review)\r\n",
        "neg_bag = bag_of_words(negative_review)\r\n",
        "\r\n",
        "print(\"Positive:\", pos_bag)\r\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
            "Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wz0D4np0BE7"
      },
      "source": [
        "###Integer Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS37nhI00Dk4",
        "outputId": "ef0fccb0-4feb-4868-d45b-30be9fe23c5f"
      },
      "source": [
        "vocab = {}  \r\n",
        "word_encoding = 1\r\n",
        "def one_hot_encoding(text):\r\n",
        "  global word_encoding\r\n",
        "\r\n",
        "  words = text.lower().split(\" \") \r\n",
        "  encoding = []  \r\n",
        "\r\n",
        "  for word in words:\r\n",
        "    if word in vocab:\r\n",
        "      code = vocab[word]  \r\n",
        "      encoding.append(code) \r\n",
        "    else:\r\n",
        "      vocab[word] = word_encoding\r\n",
        "      encoding.append(word_encoding)\r\n",
        "      word_encoding += 1\r\n",
        "  \r\n",
        "  return encoding\r\n",
        "\r\n",
        "text = \"this is a test to see if this test will work is is test a a\"\r\n",
        "encoding = one_hot_encoding(text)\r\n",
        "print(encoding)\r\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 1, 4, 8, 9, 2, 2, 4, 3, 3]\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2HE0iLP0GcK",
        "outputId": "57360dc5-ed57-40c9-d4f0-586c32ca6059"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\r\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\r\n",
        "\r\n",
        "pos_encode = one_hot_encoding(positive_review)\r\n",
        "neg_encode = one_hot_encoding(negative_review)\r\n",
        "\r\n",
        "print(\"Positive:\", pos_encode)\r\n",
        "print(\"Negative:\", neg_encode)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: [10, 11, 12, 13, 14, 15, 5, 16, 17, 18, 19, 14, 20, 21]\n",
            "Negative: [10, 11, 12, 13, 14, 15, 5, 16, 21, 18, 19, 14, 20, 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9GbW5xP3KMS"
      },
      "source": [
        "###Word Embeddings\r\n",
        "Luckily there is a third method that is far superior, word embeddings. This method keeps the order of words intact as well as encodes similar words with very similar labels. It attempts to not only encode the frequency and order of words but the meaning of those words in the sentence. It encodes each word as a dense vector that represents its context in the sentence.\r\n",
        "\r\n",
        "Unlike the previous techniques word embeddings are learned by looking at many different training examples. You can add what's called an embedding layer to the beggining of your model and while your model trains your embedding layer will learn the correct embeddings for words. You can also use pretrained embedding layers.\r\n",
        "\r\n",
        "This is the technique we will use for our examples and its implementation will be showed later on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v5gt7wbcm2G"
      },
      "source": [
        "##Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFTSv6_Gcj3X"
      },
      "source": [
        "###Movie Review Dataset\r\n",
        "Well start by loading in the IMDB movie review dataset from keras. This dataset contains 25,000 reviews from IMDB where each one is already preprocessed and has a label as either positive or negative. Each review is encoded by integers that represents how common a word is in the entire dataset. For example, a word encoded by the integer 3 means that it is the 3rd most common word in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVbqh6nAcxHC",
        "outputId": "8ba0d550-65c7-45d1-e4ae-b1401a6084e3"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\r\n",
        "from keras.datasets import imdb\r\n",
        "from keras.preprocessing import sequence\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "VOCAB_SIZE = 88584\r\n",
        "\r\n",
        "MAXLEN = 250\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg_31QSmc1Jk"
      },
      "source": [
        "# Lets look at one review\r\n",
        "train_data[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHE-EXgCI_XZ"
      },
      "source": [
        "#Preprocessing\r\n",
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\r\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpPysJSCdLoM"
      },
      "source": [
        "#creating the model\r\n",
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\r\n",
        "    tf.keras.layers.LSTM(32),\r\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU34_0GiddPs",
        "outputId": "8fbb5f38-0d1d-45e4-da43-69f0e6b76fec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i8Q__CqkbLu",
        "outputId": "1c62ae57-f240-41b3-eabc-4f86a83c7ad2"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\r\n",
        "\r\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 49s 75ms/step - loss: 0.5201 - acc: 0.7285 - val_loss: 0.3237 - val_acc: 0.8644\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.2396 - acc: 0.9097 - val_loss: 0.4545 - val_acc: 0.8490\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.1831 - acc: 0.9327 - val_loss: 0.3165 - val_acc: 0.8722\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 47s 74ms/step - loss: 0.1437 - acc: 0.9489 - val_loss: 0.2718 - val_acc: 0.8944\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.1162 - acc: 0.9609 - val_loss: 0.2854 - val_acc: 0.8890\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 0.0986 - acc: 0.9660 - val_loss: 0.3340 - val_acc: 0.8894\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.0921 - acc: 0.9680 - val_loss: 0.3492 - val_acc: 0.8876\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.0732 - acc: 0.9774 - val_loss: 0.3573 - val_acc: 0.8860\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 0.0708 - acc: 0.9772 - val_loss: 0.4795 - val_acc: 0.8698\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 0.0613 - acc: 0.9811 - val_loss: 0.3719 - val_acc: 0.8822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8evFohPkgIM",
        "outputId": "e1bd959c-5a8a-465e-9e39-aa0ddd01af87"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\r\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4437 - acc: 0.8595\n",
            "[0.4437308609485626, 0.8595200181007385]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mVkaHiNknaM",
        "outputId": "7af13fd2-cf1b-4272-f27e-12989f10106a"
      },
      "source": [
        "#making prediction\r\n",
        "word_index = imdb.get_word_index()\r\n",
        "\r\n",
        "def encode_text(text):\r\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\r\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\r\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\r\n",
        "\r\n",
        "text = \"that movie was just amazing, so amazing\"\r\n",
        "encoded = encode_text(text)\r\n",
        "print(encoded)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3kIfcKDk6Vf",
        "outputId": "a90cc13f-f9e0-4bda-ee49-e886dd27e323"
      },
      "source": [
        "# while were at it lets make a decode function\r\n",
        "\r\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\r\n",
        "\r\n",
        "def decode_integers(integers):\r\n",
        "    PAD = 0\r\n",
        "    text = \"\"\r\n",
        "    for num in integers:\r\n",
        "      if num != PAD:\r\n",
        "        text += reverse_word_index[num] + \" \"\r\n",
        "\r\n",
        "    return text[:-1]\r\n",
        "  \r\n",
        "print(decode_integers(encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that movie was just amazing so amazing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAUl3Zyak9pz",
        "outputId": "10fa3365-9693-4251-f0a9-54c7de9d2e9a"
      },
      "source": [
        "# now time to make a prediction\r\n",
        "\r\n",
        "def predict(text):\r\n",
        "  encoded_text = encode_text(text)\r\n",
        "  pred = np.zeros((1,250))\r\n",
        "  pred[0] = encoded_text\r\n",
        "  result = model.predict(pred) \r\n",
        "  print(result[0])\r\n",
        "\r\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\r\n",
        "predict(positive_review)\r\n",
        "\r\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\r\n",
        "predict(negative_review)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9382533]\n",
            "[0.38478953]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}